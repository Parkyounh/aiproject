import sys
import torch
import numpy as np
from PIL import Image
import weaviate
from weaviate.classes.data import DataObject
from weaviate.classes.config import Configure, Property, DataType
from weaviate.classes.query import MetadataQuery
import warnings
import pillow_heif
pillow_heif.register_heif_opener() 
warnings.filterwarnings('ignore')

# rembg ë° CLIP
try:
    from rembg import remove
    import clip
except ImportError:
    print("ðŸš¨ ì˜¤ë¥˜: rembg ë˜ëŠ” CLIP ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'pip install rembg clip' ì‹¤í–‰")
    sys.exit()

# í™˜ê²½ ë³€ìˆ˜
WEAVIATE_HOST = "localhost"
WEAVIATE_PORT = 8090
WEAVIATE_CLASS_NAME = "ImageObject"
GRPC_PORT = 50051

# CLIP ëª¨ë¸
device = "cuda" if torch.cuda.is_available() else "cpu"
try:
    CLIP_MODEL, PREPROCESS = clip.load("ViT-B/32", device=device)
    CLIP_MODEL.eval()
except Exception as e:
    print(f"âŒ CLIP ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
    sys.exit()

# -----------------------------------------------------------
# Weaviate ì—°ê²° ( ðŸ”¥ SDK 4.x ìµœì‹  ë°©ì‹ )
# -----------------------------------------------------------

def connect_to_weaviate():
    try:
        client = weaviate.connect_to_local(
            host=WEAVIATE_HOST,
            port=WEAVIATE_PORT,
            grpc_port=GRPC_PORT
        )
        client.is_live()
        return client
    except Exception as e:
        print(f"âŒ Weaviate í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì‹¤íŒ¨: {e}")
        sys.exit()

# -----------------------------------------------------------
# ì´ë¯¸ì§€ ì²˜ë¦¬
# -----------------------------------------------------------

def remove_background(image: Image.Image) -> Image.Image:
    try:
        output_rgba = remove(image.convert("RGB"))
        alpha = output_rgba.split()[-1]
        bg = Image.new('RGB', output_rgba.size, (0, 0, 0))
        bg.paste(output_rgba, mask=alpha)
        return bg
    except Exception:
        return image.convert("RGB")

def image_to_vector(image: Image.Image, remove_bg: bool = True) -> list:
    if remove_bg:
        image_processed = remove_background(image)
    else:
        image_processed = image.convert("RGB")

    img_input = PREPROCESS(image_processed).unsqueeze(0).to(device)

    with torch.no_grad():
        features = CLIP_MODEL.encode_image(img_input)
        features /= features.norm(dim=-1, keepdim=True)

    return features.cpu().numpy().flatten().tolist()
