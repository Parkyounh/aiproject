import pandas as pd
import mysql.connector
from mysql.connector import errorcode
import json
import os

# --- âš™ï¸ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„¤ì • ---
DB_CONFIG = {
    'user': 'root',
    'password': '1234',
    'host': '127.0.0.1',
    'port': 3305,
    'database': 'aiproject'
}
TABLE_NAME = 'review'
CSV_FILE_PATH = 'review.csv'

# âš ï¸ [í•„ìˆ˜ ìˆ˜ì •]: ì‹¤ì œ 'review' í…Œì´ë¸”ì˜ ì»¬ëŸ¼ ëª©ë¡ê³¼ ìˆœì„œì— ë§ê²Œ ìˆ˜ì •í•˜ì„¸ìš”.
DB_COLUMNS = [
    'review_id', 'product_id', 'rating', 'platform', 'review_date', 
    'review_text', 'review_images' 
]


# --- ğŸ’¡ JSON í˜•ì‹ í•„ë“œ ì²˜ë¦¬ í•¨ìˆ˜ (í•„ìš”í•œ ê²½ìš°) ---
def to_json_str(value):
    """NaN/None ê°’ì„ ì²˜ë¦¬í•˜ê³ , Python ê°ì²´ë¥¼ JSON ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    if pd.isna(value) or value is None:
        return None
    try:
        json.loads(value)
        return value
    except (TypeError, json.JSONDecodeError):
        # ìœ íš¨í•œ JSONì´ ì•„ë‹ˆë©´ JSON ë¬¸ìì—´ë¡œ ë¤í”„
        return json.dumps(value, ensure_ascii=False)


# --- ğŸ’¾ ë°ì´í„° ì‚½ì… í•¨ìˆ˜ ---
def insert_data_to_mysql(df):
    """DataFrameì˜ ë°ì´í„°ë¥¼ MySQL í…Œì´ë¸”ì— ì‚½ì…í•©ë‹ˆë‹¤."""
    
    # 'image_urls', 'metadata' ë“± JSONìœ¼ë¡œ ì €ì¥ë  ì»¬ëŸ¼ ì²˜ë¦¬ (í•„ìš”ì— ë”°ë¼ ìˆ˜ì •/ì¶”ê°€)
    json_cols = ['image_urls', 'metadata']
    for col in json_cols:
        if col in df.columns:
            df[col] = df[col].apply(to_json_str)

    # âœ… DB_COLUMNS ê¸°ì¤€ìœ¼ë¡œ ìµœì¢… ì‚½ì…í•  ì»¬ëŸ¼ë§Œ í•„í„°ë§
    df_to_insert = df[[col for col in DB_COLUMNS if col in df.columns]].copy()

    conn = None
    cursor = None
    try:
        print(f"[{DB_CONFIG['database']}] ë°ì´í„°ë² ì´ìŠ¤ì— ì—°ê²° ì¤‘...")
        conn = mysql.connector.connect(**DB_CONFIG)
        cursor = conn.cursor()
        print("âœ… ì—°ê²° ì„±ê³µ")

        # ì‚½ì… ì¿¼ë¦¬ì— ì‚¬ìš©í•  ì»¬ëŸ¼ ëª©ë¡
        columns = ', '.join(df_to_insert.columns)
        placeholders = ', '.join(['%s'] * len(df_to_insert.columns))
        
        # INSERT ... ON DUPLICATE KEY UPDATE ì¿¼ë¦¬ ìƒì„±
        # review_idê°€ PRIMARY KEY ê°€ì •. ì¤‘ë³µ ì‹œ content í•„ë“œ ì—…ë°ì´íŠ¸ ì˜ˆì‹œ
        update_cols = [f'{col}=VALUES({col})' for col in df_to_insert.columns if col not in ['review_id']]
        
        insert_query = f"""
            INSERT INTO {TABLE_NAME} ({columns}) 
            VALUES ({placeholders}) 
            ON DUPLICATE KEY UPDATE {', '.join(update_cols)}
        """

        total_rows = len(df_to_insert)
        print(f"ì´ {total_rows}ê°œì˜ ë°ì´í„°ë¥¼ ì‚½ì…/ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤...")
        
        # NaN/None ê°’ì„ Noneìœ¼ë¡œ ë³€í™˜í•˜ì—¬ MySQLì— NULLë¡œ ì‚½ì…ë˜ê²Œ í•¨
        data_to_insert = []
        for _, row in df_to_insert.iterrows():
            clean_row = [None if pd.isna(v) else v for v in row]
            data_to_insert.append(tuple(clean_row))

        cursor.executemany(insert_query, data_to_insert)
        
        conn.commit()
        print(f"âœ… {cursor.rowcount}ê°œì˜ ë ˆì½”ë“œê°€ ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")

    except mysql.connector.Error as err:
        if conn:
            conn.rollback()
        print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì˜¤ë¥˜ ({err.errno}): {err.msg}")

    except Exception as e:
        if conn:
            conn.rollback()
        print(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")

    finally:
        if cursor:
            cursor.close()
        if conn and conn.is_connected():
            conn.close()
            print("ğŸ”Œ MySQL ì—°ê²° ì¢…ë£Œ")


# --- ğŸš€ ë©”ì¸ ì‹¤í–‰ ë¶€ë¶„ ---
if __name__ == '__main__':
    if not os.path.exists(CSV_FILE_PATH):
        print(f"âŒ ì˜¤ë¥˜: ì§€ì •ëœ íŒŒì¼ ê²½ë¡œì— '{CSV_FILE_PATH}' íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    else:
        try:
            print(f"'{CSV_FILE_PATH}' íŒŒì¼ ì½ëŠ” ì¤‘...")
            # 'cp949' ì¸ì½”ë”©ì€ í•œê¸€ CSV íŒŒì¼ì— í”íˆ ì‚¬ìš©ë©ë‹ˆë‹¤.
            df = pd.read_csv(CSV_FILE_PATH, encoding='cp949')

            # âœ… ë¶ˆí•„ìš”í•œ ì—´ ì œê±°
            df = df.loc[:, ~df.columns.isna()]
            df = df.loc[:, df.columns != 'nan']
            df = df.loc[:, ~df.columns.str.contains('^Unnamed', na=False)]
            
            # ğŸ’¡ [í•„ìˆ˜]: review_date ì»¬ëŸ¼ì´ ìˆë‹¤ë©´ DATE í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            if 'review_date' in df.columns:
                df['review_date'] = pd.to_datetime(df['review_date'], errors='coerce').dt.date

            # ğŸ’¡ [í•„ìˆ˜]: rating ë° helpful_count ì»¬ëŸ¼ ì •ìˆ˜í˜• ë³€í™˜ (ì˜¤ë¥˜ ë°©ì§€)
            for col in ['rating', 'helpful_count']:
                if col in df.columns:
                    df[col] = df[col].astype(str).str.replace(r'[^\d.]', '', regex=True)
                    df[col] = pd.to_numeric(df[col], errors='coerce')
                    df[col] = df[col].fillna(0).astype('Int64').where(pd.notnull, None)


            # ìµœì¢… ê²°ì¸¡ê°’ ì²˜ë¦¬ (NaNì„ Noneìœ¼ë¡œ ë³€í™˜)
            df = df.where(pd.notnull(df), None)

            # ìµœì¢… ì‚½ì… ëŒ€ìƒ ì»¬ëŸ¼ í™•ì¸
            final_cols = [col for col in DB_COLUMNS if col in df.columns]
            print("CSV ë°ì´í„°ì—ì„œ ì¶”ì¶œëœ ìµœì¢… ì»¬ëŸ¼ ëª©ë¡:", final_cols)

            if df.empty or not final_cols:
                print("âš ï¸ ê²½ê³ : í•„í„°ë§ í›„ ì‚½ì…í•  ë°ì´í„°ê°€ ì—†ê±°ë‚˜ ì»¬ëŸ¼ì´ DB ì»¬ëŸ¼ ëª©ë¡ê³¼ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            else:
                insert_data_to_mysql(df)

        except FileNotFoundError:
            print(f"âŒ ì˜¤ë¥˜: '{CSV_FILE_PATH}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"âŒ íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")