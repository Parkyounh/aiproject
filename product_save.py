import pandas as pd
import mysql.connector
from mysql.connector import errorcode
import json
import os

# --- âš™ï¸ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„¤ì • ---
DB_CONFIG = {
    'user': 'root',
    'password': '1234',
    'host': '127.0.0.1',
    'port': 3305,
    'database': 'aiproject'
}
TABLE_NAME = 'product'
CSV_FILE_PATH = 'product.csv'

# DB í…Œì´ë¸”ì˜ ì‹¤ì œ ì»¬ëŸ¼ ëª©ë¡
DB_COLUMNS = [
    'product_id', 'categori_id', 'images', 'name', 'add_date',
    'min_price', 'max_price', 'manufacturer', 'price_trend', 'details',
    'average_rating', 'review_count', 'rating_distribution', 'review_tags', 'url'
]


# --- ğŸ’¡ JSON í˜•ì‹ í•„ë“œ ì²˜ë¦¬ í•¨ìˆ˜ ---
def to_json_str(value):
    """NaN/None ê°’ì„ ì²˜ë¦¬í•˜ê³ , Python ê°ì²´ë¥¼ JSON ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    if pd.isna(value) or value is None:
        return None
    try:
        # ì´ë¯¸ ìœ íš¨í•œ JSON ë¬¸ìì—´ì¸ì§€ í™•ì¸
        json.loads(value)
        return value
    except (TypeError, json.JSONDecodeError):
        # ìœ íš¨í•œ JSONì´ ì•„ë‹ˆë©´ JSON ë¬¸ìì—´ë¡œ ë¤í”„í•˜ì—¬ ë°˜í™˜
        return json.dumps(value, ensure_ascii=False)


# --- ğŸ’¾ ë°ì´í„° ì‚½ì… í•¨ìˆ˜ ---
def insert_data_to_mysql(df):
    """DataFrameì˜ ë°ì´í„°ë¥¼ MySQL í…Œì´ë¸”ì— ì‚½ì…í•©ë‹ˆë‹¤."""
    
    # 'price_trend', 'details', 'rating_distribution', 'review_tags' ì»¬ëŸ¼ JSON ì²˜ë¦¬
    json_cols = ['price_trend', 'details', 'rating_distribution', 'review_tags']
    for col in json_cols:
        if col in df.columns:
            df[col] = df[col].apply(to_json_str)

    # âœ… DB_COLUMNS ê¸°ì¤€ìœ¼ë¡œ ìµœì¢… ì‚½ì…í•  ì»¬ëŸ¼ë§Œ í•„í„°ë§
    df_to_insert = df[[col for col in DB_COLUMNS if col in df.columns]].copy()

    conn = None
    cursor = None
    try:
        print(f"[{DB_CONFIG['database']}] ë°ì´í„°ë² ì´ìŠ¤ì— ì—°ê²° ì¤‘...")
        conn = mysql.connector.connect(**DB_CONFIG)
        cursor = conn.cursor()
        print("âœ… ì—°ê²° ì„±ê³µ")

        # ì‚½ì… ì¿¼ë¦¬ì— ì‚¬ìš©í•  ì»¬ëŸ¼ ëª©ë¡
        columns = ', '.join(df_to_insert.columns)
        placeholders = ', '.join(['%s'] * len(df_to_insert.columns))
        
        # INSERT ... ON DUPLICATE KEY UPDATE ì¿¼ë¦¬ ìƒì„±
        # product_idê°€ PRIMARY KEY ë˜ëŠ” UNIQUE KEYì¼ ë•Œ ì‘ë™í•˜ë©°, ì¤‘ë³µ ì‹œ name í•„ë“œë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
        insert_query = f"""
            INSERT INTO {TABLE_NAME} ({columns}) 
            VALUES ({placeholders}) 
            ON DUPLICATE KEY UPDATE name=VALUES(name)
        """

        total_rows = len(df_to_insert)
        print(f"ì´ {total_rows}ê°œì˜ ë°ì´í„°ë¥¼ ì‚½ì…/ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤...")
        
        # NaN/None ê°’ì„ Noneìœ¼ë¡œ ë³€í™˜ (MySQL NULL)
        data_to_insert = []
        for _, row in df_to_insert.iterrows():
            # pandasì˜ NaNì„ Noneìœ¼ë¡œ ë³€í™˜í•˜ì—¬ MySQLì— NULLë¡œ ì‚½ì…ë˜ê²Œ í•¨
            clean_row = [None if pd.isna(v) else v for v in row]
            data_to_insert.append(tuple(clean_row))

        # executemanyë¥¼ ì‚¬ìš©í•˜ì—¬ í•œ ë²ˆì— ì‚½ì…/ì—…ë°ì´íŠ¸ ì‹¤í–‰
        cursor.executemany(insert_query, data_to_insert)
        
        conn.commit()
        print(f"âœ… {cursor.rowcount}ê°œì˜ ë ˆì½”ë“œê°€ ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")

    except mysql.connector.Error as err:
        if conn:
            conn.rollback()
        print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì˜¤ë¥˜ ({err.errno}): {err.msg}")

    except Exception as e:
        if conn:
            conn.rollback()
        print(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")

    finally:
        if cursor:
            cursor.close()
        if conn and conn.is_connected():
            conn.close()
            print("ğŸ”Œ MySQL ì—°ê²° ì¢…ë£Œ")


# --- ğŸš€ ë©”ì¸ ì‹¤í–‰ ë¶€ë¶„ ---
if __name__ == '__main__':
    if not os.path.exists(CSV_FILE_PATH):
        print(f"âŒ ì˜¤ë¥˜: ì§€ì •ëœ íŒŒì¼ ê²½ë¡œì— '{CSV_FILE_PATH}' íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    else:
        try:
            print(f"'{CSV_FILE_PATH}' íŒŒì¼ ì½ëŠ” ì¤‘...")
            df = pd.read_csv(CSV_FILE_PATH, encoding='cp949')

            # âœ… ë¶ˆí•„ìš”í•œ ì—´ ì œê±° (í—¤ë” ê¹¨ì§ ë°©ì§€)
            df = df.loc[:, ~df.columns.isna()]
            df = df.loc[:, df.columns != 'nan']
            df = df.loc[:, ~df.columns.str.contains('^Unnamed', na=False)]

            # âœ… manufacturer ì»¬ëŸ¼ëª… ì •í•© ìœ ì§€
            if 'manufactuer' in df.columns:
                df.rename(columns={'manufactuer': 'manufacturer'}, inplace=True)
            
            
            # ê²°ì¸¡ê°’ ì²˜ë¦¬ (ì „ì²´ DataFrameì— ëŒ€í•´ NaNì„ Noneìœ¼ë¡œ ë³€í™˜)
            df = df.where(pd.notnull(df), None)

            # add_date DATE ë³€í™˜
            if 'add_date' in df.columns:
                df['add_date'] = pd.to_datetime(df['add_date'], errors='coerce').dt.date

            # ìµœì¢… ì‚½ì… ëŒ€ìƒ ì»¬ëŸ¼ í™•ì¸
            final_cols = [col for col in DB_COLUMNS if col in df.columns]
            print("CSV ë°ì´í„°ì—ì„œ ì¶”ì¶œëœ ìµœì¢… ì»¬ëŸ¼ ëª©ë¡:", final_cols)

            if df.empty or len(df.columns) < len(DB_COLUMNS):
                print("âš ï¸ ê²½ê³ : ì‚½ì…í•  ë°ì´í„°ê°€ ì—†ê±°ë‚˜ ì»¬ëŸ¼ ìˆ˜ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
            else:
                insert_data_to_mysql(df)

        except FileNotFoundError:
            print(f"âŒ ì˜¤ë¥˜: '{CSV_FILE_PATH}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"âŒ íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")