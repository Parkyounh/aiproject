import os
import sys
import torch
import numpy as np
from PIL import Image
import weaviate
from weaviate.classes.config import Configure, Property, DataType
from weaviate.classes.query import MetadataQuery
# ğŸš¨ DataObject importëŠ” ì´ë¯¸ ìƒë‹¨ì— ì˜ ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
from weaviate.classes.data import DataObject 
import warnings
warnings.filterwarnings('ignore')

# ğŸš¨ğŸš¨ğŸš¨ rembg ë° CLIP ë¼ì´ë¸ŒëŸ¬ë¦¬ import ğŸš¨ğŸš¨ğŸš¨
try:
    from rembg import remove
    import clip
except ImportError:
    print("ğŸš¨ ì˜¤ë¥˜: rembg ë˜ëŠ” CLIP ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'pip install rembg clip'ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
    sys.exit()

print("ğŸš€ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")

# -----------------------------------------------------------
# 0. í™˜ê²½ ë° ëª¨ë¸ ì„¤ì •
# -----------------------------------------------------------
WEAVIATE_HOST = "localhost"
WEAVIATE_PORT = 8090  # ğŸš¨ 8090 í¬íŠ¸ ì‚¬ìš© í™•ì¸
WEAVIATE_CLASS_NAME = "ImageObject"

# CLIP ëª¨ë¸ ì§ì ‘ ë¡œë“œ (Pythonì´ ë²¡í„°ë¥¼ ìƒì„±)
device = "cuda" if torch.cuda.is_available() else "cpu"
try:
    clip_model, preprocess = clip.load("ViT-B/32", device=device)
    clip_model.eval()
    print(f"âœ… CLIP ëª¨ë¸ ë¡œë“œ ì™„ë£Œ. (Device: {device})")
except Exception as e:
    print(f"âŒ CLIP ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
    sys.exit()

# -----------------------------------------------------------
# 1. ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ë° ë²¡í„° ë³€í™˜ í•¨ìˆ˜
# -----------------------------------------------------------

def remove_background(image: Image.Image) -> Image.Image:
    """rembgë¥¼ ì‚¬ìš©í•´ ë°°ê²½ ì œê±° í›„ ê²€ì€ìƒ‰ ë°°ê²½ìœ¼ë¡œ ë³€í™˜"""
    try:
        output_rgba = remove(image.convert("RGB"))
        alpha_channel = output_rgba.split()[-1]
        image_with_black_bg = Image.new('RGB', output_rgba.size, (0, 0, 0))
        image_with_black_bg.paste(output_rgba, mask=alpha_channel)
        return image_with_black_bg
    except Exception:
        return image.convert("RGB")

def image_to_vector(image: Image.Image, remove_bg: bool = True) -> list:
    """CLIPì„ ì‚¬ìš©í•´ ì´ë¯¸ì§€ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•˜ê³  L2 ì •ê·œí™”"""
    if remove_bg:
        image_processed = remove_background(image)
    else:
        image_processed = image.convert("RGB")

    image_input = preprocess(image_processed).unsqueeze(0).to(device)

    with torch.no_grad():
        image_features = clip_model.encode_image(image_input)
        image_features /= image_features.norm(dim=-1, keepdim=True)

    return image_features.cpu().numpy().flatten().tolist()

# ==========================
# 2. Weaviate í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ë° ìŠ¤í‚¤ë§ˆ ì„¤ì •
# ==========================

# 1. í´ë¼ì´ì–¸íŠ¸ ì—°ê²° (Docker ì„œë²„ì— ì—°ê²°)
try:
    client = weaviate.connect_to_local(
        host=WEAVIATE_HOST,
        port=WEAVIATE_PORT, # 8090 í¬íŠ¸ ì‚¬ìš©
        grpc_port=50051
    )
    client.is_live()
    print(f"âœ… Weaviate í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì„±ê³µ. (Docker Server: {WEAVIATE_HOST}:{WEAVIATE_PORT})")
except Exception as e:
    print(f"âŒ Weaviate í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì‹¤íŒ¨. Docker ì»¨í…Œì´ë„ˆê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.")
    print(f"ì˜¤ë¥˜: {e}")
    sys.exit()

# 2. ì»¬ë ‰ì…˜ ì •ì˜ ë° ìƒì„±
try:
    if client.collections.exists(WEAVIATE_CLASS_NAME):
        client.collections.delete(WEAVIATE_CLASS_NAME)
        print(f"ğŸ—‘ï¸ ê¸°ì¡´ ì»¬ë ‰ì…˜ '{WEAVIATE_CLASS_NAME}' ì‚­ì œ ì™„ë£Œ.")

    collection = client.collections.create(
        name=WEAVIATE_CLASS_NAME,
        vectorizer_config=Configure.Vectorizer.none(),
        properties=[
            Property(name="imagePath", data_type=DataType.TEXT, description="ì›ë³¸ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ"),
        ]
    )
    print(f"âœ¨ Weaviate ì»¬ë ‰ì…˜ '{WEAVIATE_CLASS_NAME}' ìƒì„± ì™„ë£Œ.")

except Exception as e:
    print(f"âŒ ì»¬ë ‰ì…˜ ìƒì„± ì‹¤íŒ¨: {e}")
    sys.exit()
    
# ==========================
# 3. ë°ì´í„° ë¡œë“œ ë° ì—…ë¡œë“œ (ìµœì¢… ìˆ˜ì •: DataObject ì‚¬ìš©)
# ==========================
image_dir = "images"
image_paths = [os.path.join(image_dir, f) for f in os.listdir(image_dir)
               if f.lower().endswith((".png", ".jpg", ".jpeg", ".webp"))]

if len(image_paths) == 0:
    print(f"âŒ '{image_dir}' í´ë”ì— ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤!")
    sys.exit()

# ğŸš¨ ì»¬ë ‰ì…˜ ê°ì²´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤. ğŸš¨
collection = client.collections.get(WEAVIATE_CLASS_NAME)

# ğŸš¨ ì‚½ì…í•  ê°ì²´ë“¤ì„ DataObjectë¡œ ë¦¬ìŠ¤íŠ¸ì— ëª¨ìë‹ˆë‹¤. ğŸš¨
data_objects_to_insert = []
print("\nğŸ”„ ë°ì´í„° ê°ì²´ ë° ë²¡í„° ìƒì„± ì‹œì‘...")

for path in image_paths:
    print(f"ğŸ”¹ Processing: {path}")
    
    try:
        input_image_pil = Image.open(path)
        # Pythonì—ì„œ ì§ì ‘ ë²¡í„°ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
        vector = image_to_vector(input_image_pil, remove_bg=True)

        # ğŸš¨ğŸš¨ğŸš¨ ì¶”ê°€ëœ ê²€ì¦ ë¡œì§ ì‹œì‘ ğŸš¨ğŸš¨ğŸš¨
        if vector and len(vector) > 0:
            print(f"âœ… Vector OK: Length={len(vector)}, First Value={vector[0]:.6f}")
        else:
            # ë²¡í„° ìƒì„±ì— ì‹¤íŒ¨í–ˆê±°ë‚˜ ë¹„ì–´ìˆëŠ” ê²½ìš° ê²½ê³ ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
            print(f"âŒ WARNING: Vector is EMPTY or None for {path}. Skipping or may cause DB errors.")
            # ë²¡í„°ê°€ ë¹„ì–´ìˆìœ¼ë©´ ë‹¤ìŒ íŒŒì¼ë¡œ ë„˜ì–´ê°€ëŠ” ê²ƒì´ ì•ˆì „í•©ë‹ˆë‹¤.
            if not vector:
                continue 
        # ğŸš¨ğŸš¨ğŸš¨ ì¶”ê°€ëœ ê²€ì¦ ë¡œì§ ë ğŸš¨ğŸš¨ğŸš¨
        
        data_object_properties = {
            "imagePath": path,
        }
        
        # ğŸš¨ DataObject í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ê°ì²´ ìƒì„± ë° ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€ (ë¬¸ì œ í•´ê²° êµ¬ë¬¸) ğŸš¨
        data_objects_to_insert.append(
            DataObject(
                properties=data_object_properties,
                vector=vector
            )
        )
        
    except Exception as e:
        print(f"âŒ íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜ ({path}): {e}")

# ğŸš¨ insert_manyë¥¼ ì‚¬ìš©í•˜ì—¬ í•œ ë²ˆì— ë°ì´í„° ì‚½ì… ğŸš¨
print(f"\nğŸ“¦ Weaviateì— {len(data_objects_to_insert)}ê°œ ë°ì´í„° ì „ì†¡ ì¤‘...")

try:
    # insert_manyëŠ” DataObject ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ì•„ ìë™ìœ¼ë¡œ ë°°ì¹˜ ì „ì†¡í•©ë‹ˆë‹¤.
    collection.data.insert_many(data_objects_to_insert)
    print(f"\nâœ… All {len(data_objects_to_insert)} images processed and sent to Weaviate for indexing.")

except Exception as e:
    print(f"\nâŒ Weaviate ì‚½ì… ìµœì¢… ì‹¤íŒ¨: {e}")
    sys.exit()

# ==========================
# 4. ìœ ì‚¬ë„ ê²€ìƒ‰ (Weaviate ì‚¬ìš©)
# ==========================
query_image_path = image_paths[0] 

try:
    query_image_pil = Image.open(query_image_path)
    query_vector = image_to_vector(query_image_pil, remove_bg=True)
except Exception as e:
    print(f"âŒ ì¿¼ë¦¬ ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
    sys.exit()

print(f"\nğŸ“Š Weaviate ë²¡í„° ê²€ìƒ‰ ì¤‘... (Query: {query_image_path})")

result = collection.query.near_vector(
    near_vector=query_vector,
    limit=5,
    return_metadata=MetadataQuery(distance=True)
)

# 3. ê²°ê³¼ ì¶œë ¥
print("\n" + "=" * 50)
print(f"âœ¨ ìµœì¢… ìœ ì‚¬ë„ ê²€ìƒ‰ ê²°ê³¼ (Weaviate Vector DB)")
print("=" * 50)
print(f"ğŸ” Query Image: {query_image_path}")

if result.objects:
    print("ğŸ“¸ Most similar images:")
    for rank, item in enumerate(result.objects):
        path = item.properties["imagePath"]
        distance = item.metadata.distance
        
        if path == query_image_path:
            print(f"â­ Query itself: {path} (distance: {distance:.4f})")
        else:
            similarity = 1 - distance
            print(f"{rank+1}. {path} (similarity: {similarity:.4f} / distance: {distance:.4f})")
else:
    print("âŒ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. Weaviate ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

print("=" * 50)